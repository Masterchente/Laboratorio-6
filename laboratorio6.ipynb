{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte I. \n",
    "\n",
    "Programa y valida el Clasificador de la Distancia Mínima, valídalo con 3 datasets (Iris, Wine y Digits) y los siguientes métodos de validación. \n",
    "\n",
    "Hold-Out 70/30 estratificado\n",
    "10-Fold Cross-Validation estratificado\n",
    "Leave-One-Out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datasets utilizando Scikit-learn.\n",
    "Implementamos el Clasificador de la Distancia Mínima.\n",
    "Validamos los resultados usando los tres métodos de validación: Hold-Out (70/30 estratificado), 10-Fold Cross-Validation estratificado, y Leave-One-Out.\n",
    "Calculamos las métricas de desempeño (Accuracy y Matriz de Confusión)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: Iris\n",
      "Hold-Out Accuracy: 0.9111111111111111\n",
      "Hold-Out Confusion Matrix:\n",
      "[[15  0  0]\n",
      " [ 0 14  1]\n",
      " [ 0  3 12]]\n",
      "10-Fold CV Accuracy: 0.9200000000000002\n",
      "Leave-One-Out Accuracy: 0.92\n",
      "\n",
      "Dataset: Wine\n",
      "Hold-Out Accuracy: 0.7222222222222222\n",
      "Hold-Out Confusion Matrix:\n",
      "[[15  0  3]\n",
      " [ 0 14  7]\n",
      " [ 0  5 10]]\n",
      "10-Fold CV Accuracy: 0.7245098039215687\n",
      "Leave-One-Out Accuracy: 0.7247191011235955\n",
      "\n",
      "Dataset: Digits\n",
      "Hold-Out Accuracy: 0.8722222222222222\n",
      "Hold-Out Confusion Matrix:\n",
      "[[52  0  0  0  2  0  0  0  0  0]\n",
      " [ 0 36  7  0  0  1  2  0  3  6]\n",
      " [ 1  3 47  0  0  0  0  1  1  0]\n",
      " [ 0  1  0 51  0  1  0  2  0  0]\n",
      " [ 0  2  0  0 49  0  0  2  1  0]\n",
      " [ 0  0  0  0  0 45  0  0  0 10]\n",
      " [ 0  1  0  0  0  0 52  0  1  0]\n",
      " [ 0  0  0  0  0  0  0 54  0  0]\n",
      " [ 0 10  1  0  0  1  0  2 38  0]\n",
      " [ 0  0  0  0  3  0  0  3  1 47]]\n",
      "10-Fold CV Accuracy: 0.9009404096834267\n",
      "Leave-One-Out Accuracy: 0.9020589872008904\n",
      "\n",
      "Resultados Generales:\n",
      "\n",
      "Dataset: Iris\n",
      "Hold-Out Accuracy: 0.9111111111111111\n",
      "10-Fold CV Accuracy: 0.9200000000000002\n",
      "Leave-One-Out Accuracy: 0.92\n",
      "Confusion Matrix (Hold-Out): [[15  0  0]\n",
      " [ 0 14  1]\n",
      " [ 0  3 12]]\n",
      "\n",
      "Dataset: Wine\n",
      "Hold-Out Accuracy: 0.7222222222222222\n",
      "10-Fold CV Accuracy: 0.7245098039215687\n",
      "Leave-One-Out Accuracy: 0.7247191011235955\n",
      "Confusion Matrix (Hold-Out): [[15  0  3]\n",
      " [ 0 14  7]\n",
      " [ 0  5 10]]\n",
      "\n",
      "Dataset: Digits\n",
      "Hold-Out Accuracy: 0.8722222222222222\n",
      "10-Fold CV Accuracy: 0.9009404096834267\n",
      "Leave-One-Out Accuracy: 0.9020589872008904\n",
      "Confusion Matrix (Hold-Out): [[52  0  0  0  2  0  0  0  0  0]\n",
      " [ 0 36  7  0  0  1  2  0  3  6]\n",
      " [ 1  3 47  0  0  0  0  1  1  0]\n",
      " [ 0  1  0 51  0  1  0  2  0  0]\n",
      " [ 0  2  0  0 49  0  0  2  1  0]\n",
      " [ 0  0  0  0  0 45  0  0  0 10]\n",
      " [ 0  1  0  0  0  0 52  0  1  0]\n",
      " [ 0  0  0  0  0  0  0 54  0  0]\n",
      " [ 0 10  1  0  0  1  0  2 38  0]\n",
      " [ 0  0  0  0  3  0  0  3  1 47]]\n"
     ]
    }
   ],
   "source": [
    "# Importamos librerías necesarias\n",
    "from sklearn.datasets import load_iris, load_wine, load_digits\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, LeaveOneOut\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Clasificador de la Distancia Mínima\n",
    "class MinimumDistanceClassifier:\n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.centroids_ = {cls: X[y == cls].mean(axis=0) for cls in self.classes_}\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            distances = {cls: np.linalg.norm(x - centroid) for cls, centroid in self.centroids_.items()}\n",
    "            predictions.append(min(distances, key=distances.get))\n",
    "        return np.array(predictions)\n",
    "\n",
    "# Cargar datasets\n",
    "datasets = {\n",
    "    \"Iris\": load_iris(),\n",
    "    \"Wine\": load_wine(),\n",
    "    \"Digits\": load_digits()\n",
    "}\n",
    "\n",
    "# Validación y Métricas\n",
    "results = {}\n",
    "\n",
    "for name, data in datasets.items():\n",
    "    X, y = data.data, data.target\n",
    "    print(f\"\\nDataset: {name}\")\n",
    "    \n",
    "    # Hold-Out 70/30 estratificado\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "    clf = MinimumDistanceClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"Hold-Out Accuracy: {acc}\")\n",
    "    print(f\"Hold-Out Confusion Matrix:\\n{cm}\")\n",
    "    \n",
    "    # 10-Fold Cross-Validation estratificado\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    cv_scores = []\n",
    "    for train_idx, test_idx in skf.split(X, y):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        cv_scores.append(accuracy_score(y_test, y_pred))\n",
    "    print(f\"10-Fold CV Accuracy: {np.mean(cv_scores)}\")\n",
    "    \n",
    "    # Leave-One-Out\n",
    "    loo = LeaveOneOut()\n",
    "    loo_scores = []\n",
    "    for train_idx, test_idx in loo.split(X):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        loo_scores.append(accuracy_score(y_test, y_pred))\n",
    "    print(f\"Leave-One-Out Accuracy: {np.mean(loo_scores)}\")\n",
    "\n",
    "    # Guardar resultados\n",
    "    results[name] = {\n",
    "        \"Hold-Out Accuracy\": acc,\n",
    "        \"10-Fold CV Accuracy\": np.mean(cv_scores),\n",
    "        \"Leave-One-Out Accuracy\": np.mean(loo_scores),\n",
    "        \"Confusion Matrix (Hold-Out)\": cm\n",
    "    }\n",
    "\n",
    "# Mostrar resultados generales\n",
    "print(\"\\nResultados Generales:\")\n",
    "for dataset, metrics in results.items():\n",
    "    print(f\"\\nDataset: {dataset}\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte II. \n",
    "\n",
    "Programa y valida el Clasificador 1NN, valídalo con 3 datasets y los siguientes métodos de validación. \n",
    "\n",
    "Hold-Out 70/30 estratificado\n",
    "10-Fold Cross-Validation estratificado\n",
    "Leave-One-Out.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pasos que realizare a continuacion:\n",
    "\n",
    "Implementar el clasificador 1NN utilizando Scikit-learn (KNeighborsClassifier con n_neighbors=1).\n",
    "\n",
    "Usar los datasets Iris, Wine y Digits.\n",
    "\n",
    "Validar usando:\n",
    "Hold-Out 70/30 estratificado.\n",
    "10-Fold Cross-Validation estratificado.\n",
    "Leave-One-Out.\n",
    "\n",
    "Calcular las métricas: Accuracy y Matriz de Confusión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: Iris\n",
      "Hold-Out Accuracy: 0.9333333333333333\n",
      "Hold-Out Confusion Matrix:\n",
      "[[15  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  3 12]]\n",
      "10-Fold CV Accuracy: 0.9600000000000002\n",
      "Leave-One-Out Accuracy: 0.96\n",
      "\n",
      "Dataset: Wine\n",
      "Hold-Out Accuracy: 0.7037037037037037\n",
      "Hold-Out Confusion Matrix:\n",
      "[[14  3  1]\n",
      " [ 1 15  5]\n",
      " [ 1  5  9]]\n",
      "10-Fold CV Accuracy: 0.7300653594771241\n",
      "Leave-One-Out Accuracy: 0.7696629213483146\n",
      "\n",
      "Dataset: Digits\n",
      "Hold-Out Accuracy: 0.987037037037037\n",
      "Hold-Out Confusion Matrix:\n",
      "[[54  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 55  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 53  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 55  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 54  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 54  0  0  0  1]\n",
      " [ 0  0  0  0  0  0 54  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 54  0  0]\n",
      " [ 0  3  0  1  0  0  0  0 48  0]\n",
      " [ 0  0  0  0  1  0  0  0  1 52]]\n",
      "10-Fold CV Accuracy: 0.9894227188081937\n",
      "Leave-One-Out Accuracy: 0.988313856427379\n",
      "\n",
      "Resultados Generales:\n",
      "\n",
      "Dataset: Iris\n",
      "Hold-Out Accuracy: 0.9333333333333333\n",
      "10-Fold CV Accuracy: 0.9600000000000002\n",
      "Leave-One-Out Accuracy: 0.96\n",
      "Confusion Matrix (Hold-Out): [[15  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  3 12]]\n",
      "\n",
      "Dataset: Wine\n",
      "Hold-Out Accuracy: 0.7037037037037037\n",
      "10-Fold CV Accuracy: 0.7300653594771241\n",
      "Leave-One-Out Accuracy: 0.7696629213483146\n",
      "Confusion Matrix (Hold-Out): [[14  3  1]\n",
      " [ 1 15  5]\n",
      " [ 1  5  9]]\n",
      "\n",
      "Dataset: Digits\n",
      "Hold-Out Accuracy: 0.987037037037037\n",
      "10-Fold CV Accuracy: 0.9894227188081937\n",
      "Leave-One-Out Accuracy: 0.988313856427379\n",
      "Confusion Matrix (Hold-Out): [[54  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 55  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 53  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 55  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 54  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 54  0  0  0  1]\n",
      " [ 0  0  0  0  0  0 54  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 54  0  0]\n",
      " [ 0  3  0  1  0  0  0  0 48  0]\n",
      " [ 0  0  0  0  1  0  0  0  1 52]]\n"
     ]
    }
   ],
   "source": [
    "# Importamos librerías necesarias\n",
    "from sklearn.datasets import load_iris, load_wine, load_digits\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, LeaveOneOut\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Cargar datasets\n",
    "datasets = {\n",
    "    \"Iris\": load_iris(),\n",
    "    \"Wine\": load_wine(),\n",
    "    \"Digits\": load_digits()\n",
    "}\n",
    "\n",
    "# Validación y Métricas\n",
    "results = {}\n",
    "\n",
    "for name, data in datasets.items():\n",
    "    X, y = data.data, data.target\n",
    "    print(f\"\\nDataset: {name}\")\n",
    "    \n",
    "    # Clasificador 1NN\n",
    "    knn = KNeighborsClassifier(n_neighbors=1)\n",
    "    \n",
    "    # Hold-Out 70/30 estratificado\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"Hold-Out Accuracy: {acc}\")\n",
    "    print(f\"Hold-Out Confusion Matrix:\\n{cm}\")\n",
    "    \n",
    "    # 10-Fold Cross-Validation estratificado\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    cv_scores = []\n",
    "    for train_idx, test_idx in skf.split(X, y):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_test)\n",
    "        cv_scores.append(accuracy_score(y_test, y_pred))\n",
    "    print(f\"10-Fold CV Accuracy: {np.mean(cv_scores)}\")\n",
    "    \n",
    "    # Leave-One-Out\n",
    "    loo = LeaveOneOut()\n",
    "    loo_scores = []\n",
    "    for train_idx, test_idx in loo.split(X):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_test)\n",
    "        loo_scores.append(accuracy_score(y_test, y_pred))\n",
    "    print(f\"Leave-One-Out Accuracy: {np.mean(loo_scores)}\")\n",
    "\n",
    "    # Guardar resultados\n",
    "    results[name] = {\n",
    "        \"Hold-Out Accuracy\": acc,\n",
    "        \"10-Fold CV Accuracy\": np.mean(cv_scores),\n",
    "        \"Leave-One-Out Accuracy\": np.mean(loo_scores),\n",
    "        \"Confusion Matrix (Hold-Out)\": cm\n",
    "    }\n",
    "\n",
    "# Mostrar resultados generales\n",
    "print(\"\\nResultados Generales:\")\n",
    "for dataset, metrics in results.items():\n",
    "    print(f\"\\nDataset: {dataset}\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
